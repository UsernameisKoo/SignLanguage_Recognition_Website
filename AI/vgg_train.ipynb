{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","machine_shape":"hm","mount_file_id":"1_hO3YgVwLFXkpWy_Op0L6n6cVda-7X5d","authorship_tag":"ABX9TyN5MkMJqyH5s9uvUjDxC/6Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"0KorA8_16Th8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"metadata":{"id":"tEAIlNw-AcsG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p ~/.kaggle\n","!mv kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"ddZTlepq6Vm9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTuzkVLa6Nr9"},"outputs":[],"source":["import kagglehub\n","\n","# Download latest version\n","data_dir = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n","\n","print(\"Path to dataset files:\", data_dir)"]},{"cell_type":"code","source":["import os\n","\n","# 경로 설정\n","dataset_path = \"/root/.cache/kagglehub/datasets/grassknoted/asl-alphabet/versions/1/asl_alphabet_train/asl_alphabet_train\"\n","\n","# 경로에 있는 폴더와 파일 나열\n","if os.path.exists(dataset_path):\n","    folder_contents = os.listdir(dataset_path)\n","    print(\"경로 아래의 폴더 및 파일:\")\n","    for item in folder_contents:\n","        print(item)\n","else:\n","    print(f\"경로가 존재하지 않습니다: {dataset_path}\")"],"metadata":{"id":"YjXBOPb9B85P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","from PIL import Image\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader, Dataset, Subset\n","from torchvision import transforms, models\n","from sklearn.model_selection import train_test_split\n","import time\n","\n","# 학습률 설정\n","learning_rates = 0.000001\n","\n","# 데이터셋 정의\n","class GestureDataset(Dataset):\n","    def __init__(self, data_dir, labels, transform=None, img_size=64):\n","        self.data_dir = data_dir\n","        self.labels = labels\n","        self.transform = transform\n","        self.img_size = img_size\n","        self.image_paths = []\n","        self.targets = []\n","\n","        for label in self.labels:\n","            folder_path = os.path.join(data_dir, label)\n","            if not os.path.exists(folder_path):\n","                continue\n","            for img_name in os.listdir(folder_path):\n","                img_path = os.path.join(folder_path, img_name)\n","                self.image_paths.append(img_path)\n","                self.targets.append(self.labels.index(label))\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        label = self.targets[idx]\n","        img = Image.open(img_path).resize((self.img_size, self.img_size))\n","        if self.transform:\n","            img = self.transform(img)\n","        return img, label\n","\n","\n","# 데이터 경로 설정 및 라벨 정의\n","data_dir = os.path.join(data_dir, \"asl_alphabet_train/asl_alphabet_train\")\n","alphabet_labels = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\n","\n","# 데이터 증강 설정\n","train_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# 데이터셋 및 데이터 분할\n","full_dataset = GestureDataset(data_dir=data_dir, labels=alphabet_labels, transform=train_transform, img_size=64)\n","\n","train_idx, test_idx = train_test_split(np.arange(len(full_dataset)), test_size=0.2, random_state=42)\n","train_idx, val_idx = train_test_split(train_idx, test_size=0.1, random_state=42)\n","\n","train_dataset = Subset(full_dataset, train_idx)\n","val_dataset = Subset(full_dataset, val_idx)\n","test_dataset = Subset(full_dataset, test_idx)\n","\n","# DataLoader 생성 (batch_size 증가)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True, num_workers=4)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n","\n","# VGG 모델 설정\n","model = models.vgg16(pretrained=True)\n","\n","# 중간 레이어 고정\n","for param in model.features.parameters():\n","    param.requires_grad = False\n","\n","# 마지막 레이어 수정\n","model.classifier[6] = nn.Linear(in_features=4096, out_features=len(alphabet_labels))\n","\n","# GPU 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# 손실 함수 및 옵티마이저 설정\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.classifier[6].parameters(), lr=learning_rates)\n","\n","# 학습 함수\n","def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=5):\n","    best_acc = 0.0\n","    epochs_no_improve = 0\n","\n","    for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n","        model.train()\n","        running_loss = 0.0\n","\n","        for images, labels in tqdm(train_loader, desc=\"Training Batch\", leave=False):\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item() * images.size(0)\n","\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","\n","        # Validation\n","        model.eval()\n","        correct = 0\n","        with torch.no_grad():\n","            for images, labels in tqdm(val_loader, desc=\"Validation Batch\", leave=False):\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                _, preds = torch.max(outputs, 1)\n","                correct += torch.sum(preds == labels).item()\n","\n","        epoch_acc = correct / len(val_loader.dataset)\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Validation Accuracy: {epoch_acc * 100:.2f}%\")\n","\n","        if epoch_acc > best_acc:\n","            best_acc = epoch_acc\n","            epochs_no_improve = 0\n","            torch.save(model.state_dict(), '/content/drive/MyDrive/Colab_Notebooks/Projects/ASL_main/saved_model/vgg_gesture_model.pth')\n","            print(\"최고 정확도 모델이 저장되었습니다.\")\n","        else:\n","            epochs_no_improve += 1\n","            if epochs_no_improve >= patience:\n","                print(\"조기 중단 발동\")\n","                break\n","\n","    return best_acc\n","\n","# 학습 실행\n","start_time = time.time()\n","best_accuracy = train_model(model, train_loader, val_loader, criterion, optimizer)\n","elapsed_time = time.time() - start_time\n","print(f\"학습 완료! 최종 정확도: {best_accuracy * 100:.2f}%, 총 소요 시간: {elapsed_time:.2f}초\")\n"],"metadata":{"id":"fvjoXvtm3fhP"},"execution_count":null,"outputs":[]}]}