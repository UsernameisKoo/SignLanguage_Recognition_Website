{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wPCZnZFW_D_j"},"outputs":[],"source":["from google.colab import files\n","files.upload()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5PEdkr-9f5bs"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DWxgF2gpCSS3"},"outputs":[],"source":["!mkdir -p ~/.kaggle\n","!mv kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B_8S8F-MB07M"},"outputs":[],"source":["import kagglehub\n","\n","# Download latest version\n","data_dir = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n","\n","print(\"Path to dataset files:\", data_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbxKzjuUa_7t"},"outputs":[],"source":["# @title 기본 제목 텍스트\n","import os\n","from PIL import Image\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader, Dataset, Subset\n","from torchvision import transforms, models\n","from sklearn.model_selection import train_test_split\n","\n","# GPU 사용 여부 확인\n","print(\"현재 사용 중인 디바이스:\", \"GPU 사용 가능\" if torch.cuda.is_available() else \"CPU 사용 중\")\n","\n","# 학습률 설정\n","learning_rate = 0.000001\n","\n","# 데이터셋 정의\n","class GestureDataset(Dataset):\n","    def __init__(self, data_dir, labels, transform=None, img_size=64):\n","        self.data_dir = data_dir\n","        self.labels = labels\n","        self.transform = transform\n","        self.img_size = img_size\n","        self.image_paths = []\n","        self.targets = []\n","\n","        for label in self.labels:\n","            folder_path = os.path.join(data_dir, label)\n","            if not os.path.exists(folder_path):\n","                continue\n","            for img_name in os.listdir(folder_path):\n","                img_path = os.path.join(folder_path, img_name)\n","                self.image_paths.append(img_path)\n","                self.targets.append(self.labels.index(label))\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        label = self.targets[idx]\n","        img = Image.open(img_path).resize((self.img_size, self.img_size))\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        return img, label\n","\n","# 데이터 경로 설정 및 라벨 정의\n","data_dir = os.path.join(data_dir, \"asl_alphabet_train/asl_alphabet_train\")\n","alphabet_labels = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\n","\n","# 데이터 증강 설정\n","train_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.Resize((224, 224)),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","val_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((224, 224)),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# 데이터셋 및 데이터로더 생성\n","full_dataset = GestureDataset(data_dir=data_dir, labels=alphabet_labels, transform=train_transform, img_size=64)\n","train_idx, test_idx = train_test_split(np.arange(len(full_dataset)), test_size=0.2, random_state=42)\n","train_idx, val_idx = train_test_split(train_idx, test_size=0.1, random_state=42)\n","\n","train_dataset = Subset(full_dataset, train_idx)\n","val_dataset = Subset(full_dataset, val_idx)\n","test_dataset = Subset(full_dataset, test_idx)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","# MobileNetV3 모델 정의\n","model = models.mobilenet_v3_large(pretrained=True)\n","model.classifier[3] = nn.Linear(model.classifier[3].in_features, len(alphabet_labels))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# 손실 함수 및 옵티마이저 정의\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 학습 함수 정의\n","def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=5):\n","    best_acc = 0.0\n","    epochs_no_improve = 0\n","\n","    for epoch in tqdm(range(num_epochs), desc='Epochs'):\n","        model.train()\n","        running_loss = 0.0\n","        for images, labels in tqdm(train_loader, desc='Training Batches', leave=False):\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item() * images.size(0)\n","\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","\n","        # 검증\n","        model.eval()\n","        correct = 0\n","        with torch.no_grad():\n","            for images, labels in tqdm(val_loader, desc='Validation Batches', leave=False):\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                _, preds = torch.max(outputs, 1)\n","                correct += torch.sum(preds == labels).item()\n","\n","        epoch_acc = correct / len(val_loader.dataset)\n","        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Validation Accuracy: {epoch_acc * 100:.2f}%\")\n","\n","        # GPU 사용량 확인\n","        if (epoch + 1) % 5 == 0:  # 5 에포크마다 확인\n","            print(\"\\nGPU 상태 확인:\")\n","            !nvidia-smi\n","\n","        # 최상의 모델 저장\n","        if epoch_acc > best_acc:\n","            best_acc = epoch_acc\n","            epochs_no_improve = 0\n","            print(\"최고 정확도 모델이 저장되었습니다.\")\n","            torch.save(model.state_dict(), '/content/drive/MyDrive/Colab_Notebooks/Projects/ASL_main/mobilenet_gesture_model_best.pth')\n","        else:\n","            epochs_no_improve += 1\n","            print(f\"개선되지 않은 에포크 수: {epochs_no_improve}/{patience}\")\n","            if epochs_no_improve >= patience:\n","                print(\"조기 중단 발동\")\n","                break\n","\n","        # 매 에포크마다 모델 저장\n","        torch.save(model.state_dict(), f'/content/drive/MyDrive/Colab_Notebooks/Projects/ASL_main/mobilenet_gesture_model_epoch_{epoch+1}.pth')\n","        print(f\"Epoch {epoch+1} 모델이 저장되었습니다.\")\n","\n","    return best_acc\n","\n","# 학습 시작\n","best_accuracy = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100)\n","print(f\"Best Validation Accuracy: {best_accuracy * 100:.2f}%\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","private_outputs":true,"provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}